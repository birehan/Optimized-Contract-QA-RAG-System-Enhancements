{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Your Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\n",
    "   \"/home/babi/Desktop/10academy/week11/Optimized-Contract-QA-RAG-System-Enhancements/data/Evaluation Sets/Raptor Contract.txt\"\n",
    ")\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "import os\n",
    "# from google.colab import userdata\n",
    "# os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
    "openai_llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1250,\n",
    "    chunk_overlap = 100,\n",
    "    length_function = len,\n",
    "    is_separator_regex = False\n",
    ")\n",
    "#\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "print(len(split_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the Vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "vectorstore = Chroma(embedding_function=embeddings,\n",
    "                     persist_directory=\"Vectorstore/chromadb\",\n",
    "                     collection_name=\"full_documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and persist the split documents into the vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.add_documents(split_docs)\n",
    "vectorstore.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the Keyword / Sparse embeddings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "#\n",
    "bm25_retriever = BM25Retriever.from_documents(split_docs)\n",
    "bm25_retriever.k=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Reranker — Cross Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/babi/miniconda3/envs/week10/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at BAAI/bge-small-en-v1.5 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/babi/miniconda3/envs/week10/lib/python3.8/site-packages/torch/cuda/__init__.py:141: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Dict, Optional, Sequence\n",
    "from langchain.schema import Document\n",
    "from langchain.pydantic_v1 import Extra, root_validator\n",
    "\n",
    "from langchain.callbacks.manager import Callbacks\n",
    "from langchain.retrievers.document_compressors.base import BaseDocumentCompressor\n",
    "\n",
    "from sentence_transformers import CrossEncoder\n",
    "# from config import bge_reranker_large\n",
    "\n",
    "class BgeRerank(BaseDocumentCompressor):\n",
    "    #  BAAI/bge-reranker-large\n",
    "    model_name:str = 'BAAI/bge-small-en-v1.5'\n",
    "    \"\"\"Model name to use for reranking.\"\"\"\n",
    "    top_n: int = 3\n",
    "    \"\"\"Number of documents to return.\"\"\"\n",
    "    model:CrossEncoder = CrossEncoder(model_name)\n",
    "    \"\"\"CrossEncoder instance to use for reranking.\"\"\"\n",
    "\n",
    "    def bge_rerank(self,query,docs):\n",
    "        model_inputs =  [[query, doc] for doc in docs]\n",
    "        scores = self.model.predict(model_inputs)\n",
    "        results = sorted(enumerate(scores), key=lambda x: x[1], reverse=True)\n",
    "        return results[:self.top_n]\n",
    "\n",
    "\n",
    "    class Config:\n",
    "        \"\"\"Configuration for this pydantic object.\"\"\"\n",
    "\n",
    "        extra = Extra.forbid\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def compress_documents(\n",
    "        self,\n",
    "        documents: Sequence[Document],\n",
    "        query: str,\n",
    "        callbacks: Optional[Callbacks] = None,\n",
    "    ) -> Sequence[Document]:\n",
    "        \"\"\"\n",
    "        Compress documents using BAAI/bge-reranker models.\n",
    "\n",
    "        Args:\n",
    "            documents: A sequence of documents to compress.\n",
    "            query: The query to use for compressing the documents.\n",
    "            callbacks: Callbacks to run during the compression process.\n",
    "\n",
    "        Returns:\n",
    "            A sequence of compressed documents.\n",
    "        \"\"\"\n",
    "        if len(documents) == 0:  # to avoid empty api call\n",
    "            return []\n",
    "        doc_list = list(documents)\n",
    "        _docs = [d.page_content for d in doc_list]\n",
    "        results = self.bge_rerank(query, _docs)\n",
    "        final_results = []\n",
    "        for r in results:\n",
    "            doc = doc_list[r[0]]\n",
    "            doc.metadata[\"relevance_score\"] = r[1]\n",
    "            final_results.append(doc)\n",
    "        return final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate a Contextual Compression Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_transformers.embeddings_redundant_filter import EmbeddingsRedundantFilter\n",
    "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain_community.document_transformers.long_context_reorder import LongContextReorder\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "#\n",
    "vs_retriever = vectorstore.as_retriever(search_kwargs={\"k\":10})\n",
    "#\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever,vs_retriever],\n",
    "                                       weight=[0.5,0.5])\n",
    "#\n",
    "\n",
    "redundant_filter = EmbeddingsRedundantFilter(embeddings=embeddings)\n",
    "#\n",
    "reordering = LongContextReorder()\n",
    "#\n",
    "reranker = BgeRerank()\n",
    "#\n",
    "pipeline_compressor = DocumentCompressorPipeline(transformers=[redundant_filter,reordering,reranker])\n",
    "#\n",
    "compression_pipeline = ContextualCompressionRetriever(base_compressor=pipeline_compressor,\n",
    "                                                      base_retriever=ensemble_retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to display retrieved documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "  print(\n",
    "      f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n + {d.page_content}\" for i,d in enumerate(docs)])\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      " + [Reserved]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[Reserved]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      " + made, changed or revoked any material Tax election; elected or changed any method of accounting for Tax purposes; settled any Action in respect of Taxes; or entered into any Contractual Obligation in respect of Taxes with any Governmental Authority;\n",
      "opened any Facility or entered into any new line of business or closed any Facility or discontinued any line of business or any material business operations;\n",
      "entered into, adopted, terminated, modified, or amended in material respect (including by accelerating material rights or benefits under) any Material Company Contracts;\n",
      "wrote up or wrote down any of its material Assets or revalue its inventory;\n",
      "opened any new bank or deposit accounts (or materially change any existing arrangements with respect to any existing bank or deposit accounts) or granted any new powers of attorney;\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      " + Intended U.S. Tax Treatment. [ ].\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      " + Section 3.16\tContracts\t34\n",
      "Section 3.17\tRelated Party Transactions\t36\n",
      "Section 3.18\tCustomers and Suppliers\t37\n",
      "Section 3.19\tLabor Matters\t37\n",
      "Section 3.20\tLitigation; Government Orders\t37\n",
      "Section 3.21\tInsurance\t38\n",
      "Section 3.22\tNo Brokers\t38\n",
      "Section 3.23\tFull Disclosure\t38\n",
      "ARTICLE IV INDIVIDUAL REPRESENTATIONS AND WARRANTIES OF THE SELLERS.\t38\n",
      "Section 4.01\tOrganization\t39\n",
      "Section 4.02\tPower and Authorization\t39\n",
      "Section 4.03\tAuthorization of Governmental Authorities\t39\n",
      "Section 4.04\tNoncontravention\t39\n",
      "Section 4.05\tTitle\t39\n",
      "Section 4.06\tNo Brokers\t40\n",
      "ARTICLE V REPRESENTATIONS AND WARRANTIES OF THE BUYER.\t40\n",
      "Section 5.01\tOrganization\t40\n",
      "Section 5.02\tPower and Authorization\t40\n",
      "Section 5.03\tAuthorization of Governmental Authorities\t40\n",
      "Section 5.04\tNoncontravention\t40\n",
      "Section 5.05\tNo Brokers\t41\n",
      "ARTICLE VI COVENANTS OF THE PARTIES\t41\n",
      "Section 6.01\tExpenses\t41\n",
      "Section 6.02\tConfidentiality\t41\n",
      "Section 6.03\tPublicity\t42\n",
      "Section 6.04\tRelease.\t42\n",
      "Section 6.06\tD&O Tail.\t43\n",
      "Section 6.07\tFurther Assurances\t43\n",
      "ARTICLE VII TAX MATTERS\t43\n",
      "Section 7.01\tTax Sharing Agreements\t43\n",
      "Section 7.02\tCertain Taxes and Fees\t43\n",
      "Section 7.03\tCooperation on Tax Matters\t44\n",
      "ARTICLE VIII SURVIVAL; RECOURSE LIMITATIONS\t44\n",
      "Section 8.01\tSurvival\t44\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 5:\n",
      "\n",
      " + Customers and Suppliers.  Schedule 3.18 sets forth a complete and accurate list of (a) the ten largest customers of the Acquired Companies (measured by aggregate billings) during each of the 2019 and 2020 fiscal years, indicating the existing Contractual Obligations with each such customer by product or service provided and (b) the ten largest suppliers of materials, products or services to the Acquired Companies (measured by the aggregate amount purchased by the Acquired Companies) during each of the 2019 and 2020 fiscal years, indicating the Contractual Obligations for continued supply from each such supplier.  Except as disclosed on Schedule 3.18, since December 31, 2020, none of such customers or suppliers has cancelled, terminated or otherwise materially altered (including any material reduction in the rate or amount of sales or purchases or material increase in the prices charged or paid, as the case may be) or notified an Acquired Company of any intention to do any of the foregoing or otherwise threatened in writing to cancel, terminate or materially alter (including any material reduction in the rate or amount of sales or purchases or material increase in the prices charged or paid as the case may be) its relationship\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 6:\n",
      "\n",
      " + Withholding Rights.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 7:\n",
      "\n",
      " + Since December 31, 2020, no Acquired Company has made (outside of the ordinary course of business), changed or revoked any material Tax election, elected or changed any method of accounting for Tax purposes, settled any audit, assessment, dispute, proceeding or investigation in respect of a material amount of Taxes, surrendered any right to claim a Tax refund, filed any amended income or other material Tax Return, agreed to extend or otherwise waive the statute of limitations with respect to Taxes (other than in connection with extensions of time to file Tax Returns obtained in the ordinary course) or incurred any material amount of Taxes outside of the ordinary course of business.\n",
      "Employee Benefit Plans.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 8:\n",
      "\n",
      " + Absence of Certain Developments.  Since the Audited Balance Sheet Date, (a) no event, change, fact, condition or circumstance has occurred or arisen that has had, or would reasonably be expected to have, a Material Adverse Effect, and (b) except as disclosed on Schedule 3.07, the Business has been conducted in all material respects in the Ordinary Course of Business and no Acquired Company has (x) suffered any loss, damage, destruction or eminent domain taking, whether or not covered by insurance, with respect to any of its material Assets or the Business or (y) except as contemplated under this Agreement or any Ancillary Agreement, taken any action or omitted to take any of the following actions:\n",
      "amended its Organizational Documents, effected any split, combination, reclassification or similar action with respect to its capital stock or other Equity Interests or adopt or carry out any plan of complete or partial liquidation or dissolution;\n",
      "issued, sold, granted or otherwise disposed of any of its Equity Interests or other securities, or amended any term of any of its outstanding Equity Interests or other securities;\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 9:\n",
      "\n",
      " + payoff and lien release letters in form and substance reasonably satisfactory to Buyer in respect of any indebtedness (including unused commitments therefor) included in the Closing Debt Amount and the termination of all Encumbrances (other than Permitted Encumbrances) on any assets securing such indebtedness, executed by the relevant holders of such indebtedness (or the appropriate agents therefor), drafts of which shall have been provided to Buyer prior to the date hereof; \n",
      "with respect to all Options held by Vested Optionsholders and Warrantholders , an Option Cancellation Acknowledgement or a Warrant Cancellation Acknowledgement evidencing the cancellation of such Vested Options or Warrants, as applicable, effective at Closing;\n",
      "electronic copies of all documentation contained in the data room contemplated by Section 1.02(d) in a format reasonably accessible by Buyer;\n",
      "a copy of the Escrow Agreement [and Paying Agent Agreement], duly executed by the Sellers’ Representative; and\n",
      "a certificate from the Company satisfying the requirements of Treasury Regulations Section 1.1445-2(c) and a proof of mailing of a certificate to the IRS satisfying the requirements of Treasury Regulations Section 1.897-2(h)(2). [TBD]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 10:\n",
      "\n",
      " + lessors or renters under leases or rental agreements and (f) liens that arise by operation of law in the Ordinary Course of Business and are not material individually or in the aggregate.\n"
     ]
    }
   ],
   "source": [
    "pretty_print_docs(vs_retriever.get_relevant_documents(\"What are the major changes in v 0.1.0?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      " + Proposed Final Closing Statement.  Within sixty (60) calendar days after the Closing Date, the Company shall prepare or cause to be prepared, and will provide to the Sellers’ Representative, a written statement setting forth in reasonable detail its proposed final determination of the Closing Debt Amount, Closing Cash Amount, and the Seller Transaction Expenses (the “Proposed Final Closing Statement”).  The Proposed Final Closing Statement will be prepared in accordance with the Accounting Principles and without giving effect to any changes resulting from the consummation of the Contemplated Transactions on the Closing Date.  The Sellers’ Representative and its Representatives shall have reasonable access to the work papers and other books and records of the Acquired Companies and to the persons who prepared the Proposed Final Closing Statement, for purposes of assisting the Sellers’ Representative and its Representatives in their review of the Proposed Final Closing Statement.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      " + [Reserved]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[Reserved]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      " + Schedules.  Any information disclosed in any Schedule shall be deemed to be disclosed to Buyer for all purposes of this Agreement to the extent that the applicability of such disclosure is reasonably apparent on its face.  Neither the specification of any Dollar amount or any item or matter in any provision of this Agreement nor the inclusion of any specific item or matter in any Schedule is intended to imply that such amount, or higher or lower amounts, or the item or matter so specified or included, or other items or matters, are or are not material, and no Party may use the fact of the specification of any such amount or the specification or inclusion of any such item or matter in any dispute or controversy between the Parties as to whether any item or matter not specified in this Agreement or included in any Schedule is or is not material for purposes of this Agreement.  In addition, neither the specification of any item or matter in any provision of this Agreement nor the inclusion of any specific item or matter in any Schedule is intended to imply that such item or matter, or other items or matters, are or are not in the ordinary course of business or in a manner consistent with past practice, and no Party may use the fact\n"
     ]
    }
   ],
   "source": [
    "docs = compression_pipeline.get_relevant_documents(\"What are the major changes in v 0.1.0?\")\n",
    "pretty_print_docs(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a naive RAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" The Sellers are responsible for a breach of representations and warranties to the extent of their Pro Rata Percentage, unless the breach was caused by the Sellers' Representative's gross negligence, bad faith, or willful misconduct.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "#\n",
    "qa = RetrievalQA.from_chain_type(llm=openai_llm,\n",
    "                                 chain_type=\"stuff\",\n",
    "                                 retriever=vectorstore.as_retriever(search_kwargs={\"k\":5}),\n",
    "                                 return_source_documents=True)\n",
    "\n",
    "naive_response = qa(\"Under what circumstances and to what extent the Sellers are responsible for a breach of representations and warranties?\")\n",
    "naive_response[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define an Advanced RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" The Sellers are responsible for a breach of representations and warranties if it is committed by any of their Affiliates or their or their Affiliates' Representatives. However, the Sellers' liability is limited to the obligations outlined in the agreement and the Buyer cannot seek recourse from the personal assets of the Sellers' Representative.\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "#\n",
    "qa_advanced = RetrievalQA.from_chain_type(llm=openai_llm,\n",
    "                                 chain_type=\"stuff\",\n",
    "                                 retriever=compression_pipeline,\n",
    "                                 return_source_documents=True)\n",
    "#\n",
    "qa_adv_response = qa_advanced(\"Under what circumstances and to what extent the Sellers are responsible for a breach of representations and warranties?\")  \n",
    "qa_adv_response[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Naive RAG and Advanced RAG using RAGAS evaluation Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Test Set Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  50%|█████     | 5/10 [00:17<00:17,  3.43s/it]         \n",
      "Exception in thread Thread-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/babi/miniconda3/envs/week10/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/babi/miniconda3/envs/week10/lib/python3.8/site-packages/ragas/executor.py\", line 75, in run\n",
      "    results = self.loop.run_until_complete(self._aresults())\n",
      "  File \"/home/babi/miniconda3/envs/week10/lib/python3.8/asyncio/base_events.py\", line 616, in run_until_complete\n",
      "    return future.result()\n",
      "  File \"/home/babi/miniconda3/envs/week10/lib/python3.8/site-packages/ragas/executor.py\", line 63, in _aresults\n",
      "    raise e\n",
      "  File \"/home/babi/miniconda3/envs/week10/lib/python3.8/site-packages/ragas/executor.py\", line 58, in _aresults\n",
      "    r = await future\n",
      "  File \"/home/babi/miniconda3/envs/week10/lib/python3.8/asyncio/tasks.py\", line 608, in _wait_for_one\n",
      "    return f.result()  # May raise f.exception().\n",
      "  File \"/home/babi/miniconda3/envs/week10/lib/python3.8/site-packages/ragas/executor.py\", line 91, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "  File \"/home/babi/miniconda3/envs/week10/lib/python3.8/site-packages/ragas/testset/evolutions.py\", line 163, in evolve\n",
      "    return await self.generate_datarow(\n",
      "  File \"/home/babi/miniconda3/envs/week10/lib/python3.8/site-packages/ragas/testset/evolutions.py\", line 210, in generate_datarow\n",
      "    merged_nodes = self.merge_nodes(relevant_context)\n",
      "  File \"/home/babi/miniconda3/envs/week10/lib/python3.8/site-packages/ragas/testset/evolutions.py\", line 75, in merge_nodes\n",
      "    embed_dim = len(nodes.nodes[0].embedding) if nodes.nodes[0].embedding else None\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n"
     ]
    },
    {
     "ename": "ExceptionInRunner",
     "evalue": "The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exception=False` incase you want to show only a warning message instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mExceptionInRunner\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m generator \u001b[38;5;241m=\u001b[39m TestsetGenerator\u001b[38;5;241m.\u001b[39mwith_openai()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m testset \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_with_langchain_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistributions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43msimple\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_context\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/week10/lib/python3.8/site-packages/ragas/testset/generator.py:154\u001b[0m, in \u001b[0;36mTestsetGenerator.generate_with_langchain_docs\u001b[0;34m(self, documents, test_size, distributions, with_debugging_logs, is_async, raise_exceptions, run_config)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_with_langchain_docs\u001b[39m(\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    141\u001b[0m     documents: t\u001b[38;5;241m.\u001b[39mSequence[LCDocument],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    148\u001b[0m ):\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;66;03m# chunk documents and add to docstore\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdocstore\u001b[38;5;241m.\u001b[39madd_documents(\n\u001b[1;32m    151\u001b[0m         [Document\u001b[38;5;241m.\u001b[39mfrom_langchain_document(doc) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    152\u001b[0m     )\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistributions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistributions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_debugging_logs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_debugging_logs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_async\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_async\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraise_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/week10/lib/python3.8/site-packages/ragas/testset/generator.py:246\u001b[0m, in \u001b[0;36mTestsetGenerator.generate\u001b[0;34m(self, test_size, distributions, with_debugging_logs, is_async, raise_exceptions, run_config)\u001b[0m\n\u001b[1;32m    244\u001b[0m     test_data_rows \u001b[38;5;241m=\u001b[39m exec\u001b[38;5;241m.\u001b[39mresults()\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m test_data_rows \u001b[38;5;241m==\u001b[39m []:\n\u001b[0;32m--> 246\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ExceptionInRunner()\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[0;31mExceptionInRunner\u001b[0m: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exception=False` incase you want to show only a warning message instead."
     ]
    }
   ],
   "source": [
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "#\n",
    "#load documents again to avoid any kind of bias\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 200\n",
    ")\n",
    "documents = text_splitter.split_documents(documents)\n",
    "len(documents)\n",
    "#\n",
    "#\n",
    "generator = TestsetGenerator.with_openai()\n",
    "#\n",
    "testset = generator.generate_with_langchain_docs(documents, test_size=10, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset.test_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Responses with RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = testset.to_pandas()\n",
    "test_questions = test_df[\"question\"].values.tolist()\n",
    "test_groundtruths = test_df[\"ground_truth\"].values.tolist()\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate responses using our Naive RAG pipeline using the questions we’ve generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for question in test_questions:\n",
    "  response = qa.invoke({\"query\" : question})\n",
    "  answers.append(response[\"result\"])\n",
    "  contexts.append([context.page_content for context in response['source_documents']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrap the information in a Hugging Face dataset for use in the Ragas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "response_dataset = Dataset.from_dict({\n",
    "    \"question\" : test_questions,\n",
    "    \"answer\" : answers,\n",
    "    \"contexts\" : contexts,\n",
    "    \"ground_truth\" : test_groundtruths\n",
    "})\n",
    "response_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating with RAGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    answer_correctness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "metrics = [\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    answer_correctness,\n",
    "]\n",
    "#\n",
    "naive_results = evaluate(response_dataset, metrics,raise_exceptions=False)\n",
    "naive_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate responses using our Advanced RAG pipeline using the questions we’ve generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_answers = []\n",
    "adv_contexts = []\n",
    "\n",
    "for question in test_questions:\n",
    "  response = qa_advanced.invoke({\"query\" : question})\n",
    "  adv_answers.append(response[\"result\"])\n",
    "  adv_contexts.append([context.page_content for context in response['source_documents']])\n",
    "\n",
    "#wrap into huggingface dataset\n",
    "response_dataset_advanced_retrieval = Dataset.from_dict({\n",
    "    \"question\" : test_questions,\n",
    "    \"answer\" : adv_answers,\n",
    "    \"contexts\" : adv_contexts,\n",
    "    \"ground_truth\" : test_groundtruths\n",
    "})\n",
    "response_dataset_advanced_retrieval[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_retrieval_results = evaluate(response_dataset_advanced_retrieval, metrics,raise_exceptions=False)\n",
    "advanced_retrieval_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comapare the evaluations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_original = pd.DataFrame(list(naive_results.items()), columns=['Metric', 'Baseline'])\n",
    "df_comparison = pd.DataFrame(list(advanced_retrieval_results.items()), columns=['Metric', 'Contextual Compresssion with Document Stuffing'])\n",
    "\n",
    "df_merged = pd.merge(df_original, df_comparison, on='Metric')\n",
    "\n",
    "df_merged['Delta'] = df_merged['Contextual Compresssion with Document Stuffing'] - df_merged['Baseline']\n",
    "\n",
    "df_merged"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "week10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
